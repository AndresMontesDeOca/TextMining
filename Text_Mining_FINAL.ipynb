{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/TextMining/blob/main/Text_Mining_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqpzPNegV39P"
      },
      "source": [
        "<center>\n",
        "\n",
        "#### Universidad Austral<br>\n",
        "#### Maestría en Minería de Datos y Gestión del Conocimiento<br>\n",
        "#### Text Mining<br>\n",
        "#### CGC: Clasificador de Géneros Cinematográficos<br>\n",
        "\n",
        "\n",
        "#### Integrantes:<br>\n",
        "Alejandra Reyes<br>\n",
        "Andres Montes de Oca<br>\n",
        "Rafael Gimenez<br>\n",
        "Soledad Ríos<br>\n",
        "Tomas Sauro\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07FHeEy1V39Q"
      },
      "source": [
        "## Introducción\n",
        "Título: Clasificador de Géneros Cinematográficos (CGC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApR0Ias0FGw2"
      },
      "source": [
        "Nota: utilizar mas de un modelo (x modelos) y que el numero sea impar para usar criterio democratico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBzyM1gN2Yht"
      },
      "source": [
        "Problemática: En un servicio que releva los contenidos disponibles en plataformas streaming, con frecuencuencia se detectan contenidos sin información de género pero se cuenta con la sinopsis del contenido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUKFnH0n2Yrc"
      },
      "source": [
        "Nombre del servicio y empresa con la problematica: [Content Pulse | BB Media](https://bb.vision/content-pulse-en/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWiHsyCh2Xyp"
      },
      "source": [
        "Objetivo: Entrenar un modelo que dada una sinopsis sobre una película retorne los géneros del contenido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv01cZdB3-mj"
      },
      "source": [
        "Hoja de Ruta:\n",
        "\n",
        "1. Acceso a los datos\n",
        "2. Tabulación de los datos\n",
        "3. Limpieza de datos\n",
        "4. Exploración de modelos\n",
        "5. Pruebas\n",
        "6. Analísis de resultados\n",
        "7. Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnXUmMg8Zy0e"
      },
      "source": [
        "Posibles contratiempos:\n",
        "\n",
        "1. Datos faltantes, incompletos, no estandarizados.\n",
        "2. Fallar en una buena separacion de los subdataset para testing y validation (ejemplo, quedarnos con sinopsis para testing muy ricas en descripción y para validation no)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9lA9JnIkIBO"
      },
      "source": [
        "## Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn8ag4NykG76"
      },
      "outputs": [],
      "source": [
        "# Verificación e instalación\n",
        "import importlib\n",
        "import subprocess\n",
        "\n",
        "def instalar_librerias(packages):\n",
        "    [importlib.import_module(package) if package in locals() else subprocess.call(['pip', 'install', package]) for package in packages]\n",
        "\n",
        "# Lista de librerías a verificar e instalar\n",
        "listado_librerias = ['requests', 'json', 'datetime', 'gdown', 'numpy', 'pandas', 'seaborn', 'matplotlib', 'tabulate', 'scikit-learn']\n",
        "\n",
        "# Verificar e instalar las librerías\n",
        "instalar_librerias(listado_librerias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHlBRzEckNKH"
      },
      "outputs": [],
      "source": [
        "# Importación\n",
        "import requests\n",
        "import json\n",
        "import datetime\n",
        "import gdown\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ignorar Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS4oGZkTV39R"
      },
      "source": [
        "## 0. Acceso a los datos (Ejemplo con algunas variables usando la API de TMDB)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmtegSUNhb0K"
      },
      "source": [
        "Se utiliza una base de datos colaborativas con acceso abierto llamada TMDB obtenido los datos mediante su [API](https://developer.themoviedb.org/docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIHvsZY5p2iT"
      },
      "outputs": [],
      "source": [
        "# Credencial\n",
        "api_key = 'bf0a945ba271caf72a6a1b1f53a1084d'\n",
        "\n",
        "# URL base\n",
        "base_url = 'https://api.themoviedb.org/3/'\n",
        "\n",
        "# Endpoint para obtener la lista de películas y series de tv\n",
        "movie_endpoint = 'discover/movie'\n",
        "tv_endpoint = 'discover/tv'\n",
        "\n",
        "# Parámetros\n",
        "params = {\n",
        "    'api_key': api_key,\n",
        "    'sort_by': 'popularity.desc' # Se usa este orden para verificar si los datos obtenidos son correctos (los contenidos mas populares son mas conocidos siendo mas facil validar)\n",
        "}\n",
        "\n",
        "# Función para obtener nombres de actores\n",
        "def get_cast_names(content_type, content_id):\n",
        "    credits_endpoint = f'{content_type}/{content_id}/credits'\n",
        "    credits_params = {\n",
        "        'api_key': api_key\n",
        "   }\n",
        "    credits_response = requests.get(base_url + credits_endpoint, params=credits_params)\n",
        "    credits_data = credits_response.json()\n",
        "    cast_names = [actor['name'] for actor in credits_data['cast'][:3]] # Dado que los actores estan ordenados por importancia, nos quedamos con los 3 primeros (protagonistas)\n",
        "    return ', '.join(cast_names)\n",
        "\n",
        "# Función para obtener nombres de compañías de producción\n",
        "def get_production_companies(content_type, content_id):\n",
        "    details_endpoint = f'{content_type}/{content_id}'\n",
        "    details_params = {\n",
        "        'api_key': api_key\n",
        "    }\n",
        "    details_response = requests.get(base_url + details_endpoint, params=details_params)\n",
        "    details_data = details_response.json()\n",
        "    production_companies = ', '.join([company['name'] for company in details_data.get('production_companies', [])])\n",
        "    return production_companies\n",
        "\n",
        "# Realizar solicitudes GET a la API y obtener datos para películas\n",
        "movie_response = requests.get(base_url + movie_endpoint, params=params)\n",
        "movie_data = movie_response.json()\n",
        "\n",
        "# Realizar solicitudes GET a la API y obtener datos para programas de televisión\n",
        "tv_response = requests.get(base_url + tv_endpoint, params=params)\n",
        "tv_data = tv_response.json()\n",
        "\n",
        "# Procesar los resultados de películas y programas de televisión\n",
        "results_list = []\n",
        "\n",
        "for content_type, content_data in [('movie', movie_data), ('tv', tv_data)]:\n",
        "    for result in content_data['results']:\n",
        "        content_id = result['id']\n",
        "        title = result['title'] if content_type == 'movie' else result['name']\n",
        "        release_date = result['release_date'] if content_type == 'movie' else result['first_air_date']\n",
        "        overview = result['overview']\n",
        "        poster_path = result['poster_path']\n",
        "        popularity = result['popularity']\n",
        "        vote_count = result['vote_count']\n",
        "        vote_average = result['vote_average']\n",
        "\n",
        "        # Obtener nombres de actores utilizando la función\n",
        "        cast_names = get_cast_names(content_type, content_id)\n",
        "\n",
        "        # Obtener nombres de compañías de producción utilizando la nueva función\n",
        "        production_companies = get_production_companies(content_type, content_id)\n",
        "\n",
        "        results_list.append({\n",
        "            'type': content_type.capitalize(),\n",
        "            'id': content_id,\n",
        "            'title': title,\n",
        "            'release': release_date,\n",
        "            'synopsis': overview,\n",
        "            'cast': cast_names,\n",
        "            'productions': production_companies,\n",
        "            'popularity': popularity,\n",
        "            'votes': vote_count,\n",
        "            'score': vote_average,\n",
        "            'imagen': f'https://image.tmdb.org/t/p/w500{poster_path}'\n",
        "        })\n",
        "\n",
        "# DataFrame\n",
        "tmdb_base_20 = pd.DataFrame(results_list)\n",
        "tmdb_base_20.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1sYquxZjQwx"
      },
      "source": [
        "## 1. Acceso a los datos (Archivo preexistente con datos públicos previamente descargados desde TMDB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez86m_60o7ci"
      },
      "outputs": [],
      "source": [
        "# URL del archivo Excel\n",
        "url = \"https://onedrive.live.com/download?resid=B5CCCD69939F6AA3%21985&authkey=!AMd0773xIAnUL_I&em=x&app=Excel\"\n",
        "\n",
        "# Descarga del archivo en el entorno de colab\n",
        "output = \"/content/file.xlsx\"  # Ruta donde se guardará el archivo en Colab\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A6vtGNDpU9k"
      },
      "outputs": [],
      "source": [
        "# DataFrame\n",
        "contents = pd.read_excel(output)\n",
        "contents.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06FJaTLMvlRY"
      },
      "source": [
        "## 2. Exploración Inicial\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqZeMfuUvsfQ"
      },
      "outputs": [],
      "source": [
        "print('contents dataframe:', contents.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_IE_PyWv-Q_"
      },
      "outputs": [],
      "source": [
        "print(contents.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoRl8CKWxDWw"
      },
      "outputs": [],
      "source": [
        "# Verificar si el campo id contiene valores únicos\n",
        "id_is_unique = contents['id'].nunique() == len(contents['id'])\n",
        "if id_is_unique:\n",
        "    print(\"El campo 'id' tiene valores únicos.\")\n",
        "else:\n",
        "    print(\"El campo 'id' tiene valores repetidos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJU9hiOWxbMd"
      },
      "outputs": [],
      "source": [
        "# Obtener un id repetido para verificar los registros que lo contienen\n",
        "\n",
        "# Construir tabla de frecuencia por 'id'\n",
        "id_frequency_table = contents['id'].value_counts().reset_index()\n",
        "id_frequency_table.columns = ['id', 'Frequency']\n",
        "\n",
        "# Filtrar la tabla de frecuencia para encontrar el primer ID con una frecuencia mayor a uno\n",
        "firts_id_duplicated = id_frequency_table[id_frequency_table['Frequency'] > 1]['id'].iloc[0]\n",
        "\n",
        "# Mostrar los registros que contienen el primer ID repetido\n",
        "contents[contents['id'] == firts_id_duplicated]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjC7925lzFTL"
      },
      "outputs": [],
      "source": [
        "# Verificar si el campo id contiene valores únicos para cada tipo de contenido\n",
        "type_contents = ['Series', 'Movie']\n",
        "\n",
        "for type_contents in type_contents:\n",
        "    # Filtrar el DataFrame por el campo 'type' para el tipo de contenido actual\n",
        "    contents_by_type = contents[contents['type'] == type_contents]\n",
        "\n",
        "    # Verificar si el campo 'id' en el DataFrame filtrado contiene valores únicos\n",
        "    id_is_unique = contents_by_type['id'].nunique() == len(contents_by_type['id'])\n",
        "\n",
        "    if id_is_unique:\n",
        "        print(f\"El campo 'id' tiene valores únicos para el tipo de contenido '{type_contents}'.\")\n",
        "    else:\n",
        "        print(f\"El campo 'id' tiene valores repetidos para el tipo de contenido '{type_contents}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiABjWOZwc-u"
      },
      "source": [
        "####**Variables**\n",
        "\n",
        "- **id**: Identificador único (por tipo de contenido) para cada registro\n",
        "- **type**: Tipo de contenido (Movies/Series)\n",
        "- **title**: Título del contenido\n",
        "- **year**: Año de lanzamiento del contenido\n",
        "- **duration**: Duración del contenido expresada en minutos\n",
        "- **synopsis**: Reseña del contenido\n",
        "- **genres**: Géneros de los contenidos (separados con \",\" cuando hay más de uno\n",
        "- **cast**: Listado de actores (separados con \",\")\n",
        "- **directors**: director/directores del contenido (separados con \",\")\n",
        "- **url**: Direccion web del contenido en tmdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4Zmro9KGWZO"
      },
      "source": [
        "## 3. Exploración y Transformación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeaFK1JhLmyc"
      },
      "outputs": [],
      "source": [
        "# Verificación\n",
        "contents.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2rA_zkIXayL"
      },
      "outputs": [],
      "source": [
        "# Especificar variables categóricas\n",
        "var_categoricas = [col for col in contents.columns if col in ['type', 'genres']]\n",
        "\n",
        "# Convertir a categóricas las varibales correspondientes\n",
        "contents[var_categoricas] = contents[var_categoricas].astype('category')\n",
        "\n",
        "# Verificación\n",
        "contents.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InD_s089R4Pk"
      },
      "outputs": [],
      "source": [
        "contents.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94cjGxs6DlsU"
      },
      "outputs": [],
      "source": [
        "# Eliminar los registros con valor nulo en el campo synopsis\n",
        "contents.dropna(subset=['synopsis'], inplace=True)\n",
        "contents.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Niuxa4_Sq2t"
      },
      "outputs": [],
      "source": [
        "# Calcular el porcentaje de valores nulos para cada columna\n",
        "porcentaje_nulos = (contents.isnull().sum() / len(contents)) * 100\n",
        "print(\"Porcentaje de valores nulos por columna:\")\n",
        "print(porcentaje_nulos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaVhNnZpnBJC"
      },
      "outputs": [],
      "source": [
        "contents['genres'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8_-RDsooOqK"
      },
      "outputs": [],
      "source": [
        "# Crear una columna con el género principal\n",
        "contents['principal_genre'] = contents['genres'].str.split(',').str[0]\n",
        "contents.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzQc7CIukiii"
      },
      "outputs": [],
      "source": [
        "contents['principal_genre'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oChpM7iRr4dP"
      },
      "outputs": [],
      "source": [
        "# Crear la columna 'synopsis_length' que contiene la longitud de cada sinopsis\n",
        "contents['synopsis_length'] = contents['synopsis'].apply(lambda x: len(str(x)) if pd.notnull(x) else 0)\n",
        "contents['synopsis_length'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3VV7ovjtXJA"
      },
      "outputs": [],
      "source": [
        "# Crear la columna 'synopsis_length_interval' que contiene los intervalos de la longitud de cada sinopsis\n",
        "\n",
        "# Definir los límites de los intervalos\n",
        "bins = [1, 100, 200, 300, float('inf')]\n",
        "\n",
        "# Definir las etiquetas para cada intervalo\n",
        "labels = ['Muy corta', 'Corta', 'Moderada', 'Larga']\n",
        "\n",
        "# Crear el campo 'synopsis_length_interval' que asigna un intervalo a cada longitud de sinopsis\n",
        "contents['synopsis_length_interval'] = pd.cut(contents['synopsis_length'], bins=bins, labels=labels, include_lowest=True)\n",
        "contents.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE9lbxfW8EaR"
      },
      "source": [
        "## 4. Separación de dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Iq_CVa7BRV4"
      },
      "outputs": [],
      "source": [
        "# Excluir columnas con las que no se trabajara\n",
        "contents= contents.drop(['id', 'title', 'genres', 'url'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL7izy3pr28T"
      },
      "outputs": [],
      "source": [
        "# Registros sin genres (el problema a resolver)\n",
        "contents_target = contents[contents['principal_genre'].isnull()]\n",
        "\n",
        "# Registros con genres para modelar\n",
        "contents = contents.drop(contents_target.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ckcd6QvBL3Y"
      },
      "outputs": [],
      "source": [
        "# Tabla de contingencia (%) entre principal_genre synopsis_length_interval en contents\n",
        "pd.crosstab(contents['principal_genre'], contents['synopsis_length_interval'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsk_qczn8hqI"
      },
      "outputs": [],
      "source": [
        "# Dividir el DataFrame en 70% train y 30% test, estratificado por \"principal_genre\" y \"synopsis_length_interval\"\n",
        "contents_train, contents_test = train_test_split(contents, test_size=0.3, stratify=contents[['principal_genre', 'synopsis_length_interval']], random_state=2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QVoGHIYBU7K"
      },
      "outputs": [],
      "source": [
        "# Tabla de contingencia (%) entre principal_genre synopsis_length_interval en contents_train\n",
        "pd.crosstab(contents_train['principal_genre'], contents_train['synopsis_length_interval'], normalize='index') * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n-Tbqy3BjT0"
      },
      "outputs": [],
      "source": [
        "# Tabla de contingencia (%) entre principal_genre synopsis_length_interval en contents_test\n",
        "pd.crosstab(contents_test['principal_genre'], contents_test['synopsis_length_interval'], normalize='index') * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v53c1zhz-4qZ"
      },
      "source": [
        "## 5. Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Andy's Model"
      ],
      "metadata": {
        "id": "hMwz1sR9AZjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampleamos el dataset\n",
        "\n",
        "data['synopsis'] = data['synopsis']str.lower() # convertimos todo a minusculas\n",
        "data = contents[['synopsis', 'principal_genre']].sample(1000, random_state=99) # sampleamos a 1000 registros\n",
        "display(data.head())\n",
        "print('Cantidad de Generos distintos:', len(data.principal_genre.unique()))"
      ],
      "metadata": {
        "id": "qflwGKZZ9Fcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre Procesamiento"
      ],
      "metadata": {
        "id": "lphF9ncxQ6XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pattern\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from pattern.en import lemma\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')\n",
        "\n",
        "vect = TfidfVectorizer(analyzer     = \"word\",\n",
        "                       decode_error = \"ignore\",\n",
        "                       encoding     = \"str\",\n",
        "                       lowercase    = True,\n",
        "                       stop_words   = stopwords.words(\"english\"),\n",
        "                       strip_accents= \"ascii\",\n",
        "                       tokenizer    = lambda texts: [lemma(t) for t in word_tokenize(texts) if (t not in stopwords.words('english'))]\n",
        "                       )\n",
        "\n",
        "\n",
        "texts = data.synopsis.values\n",
        "data_Tfidf = vect.fit_transform(texts)\n",
        "\n",
        "X = data_Tfidf\n",
        "y = data['principal_genre']\n",
        "print(X.shape)\n",
        "\n",
        "# División de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "BQSrxxOAQ8Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "k2MoADcLUAv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# Modelos\n",
        "model1 = RandomForestClassifier()\n",
        "model2 = GradientBoostingClassifier()\n",
        "model3 = SVC()\n",
        "model4 = LogisticRegression()\n",
        "\n",
        "# Entrenamiento del modelo de clasificación multietiqueta (Regresión Logística Multietiqueta)\n",
        "classifier = MultiOutputClassifier(model4)\n",
        "classifier.fit(X_train, y_train.to_frame())\n",
        "\n",
        "# Predicción\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluación del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Precisión del modelo: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "QvIjVn4N9d7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GS4oGZkTV39R"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}